{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "lemmatizer = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('./keywords/scopus_1.csv')\n",
    "df_2 = pd.read_csv('./keywords/scopus_2.csv')\n",
    "df_3 = pd.read_csv('./keywords/scopus_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_1, df_2, df_3], ignore_index=True)\n",
    "df.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_keywords(df, columns = ['Author Keywords', 'Index Keywords']):\n",
    "    full_list = \"\"\n",
    "    for idx, row in df.iterrows():\n",
    "        for col in columns:\n",
    "            full_list += row[col] + \";\"\n",
    "    full_list = full_list.split(';')\n",
    "    full_list = [item.strip() for item in full_list]\n",
    "    full_list = list(set(full_list))\n",
    "    full_list.remove('')\n",
    "    return full_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list = get_all_keywords(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine two words with same stems into a single keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stemmed_words_list(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    text = \" \".join([word for word in word_tokenize(text) if word not in nltk.corpus.stopwords.words('english')])\n",
    "    stems = [stemmer.stem(word) for word in word_tokenize(text)]\n",
    "    final_text = stems\n",
    "    final_text = list(set(final_text))\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_keywords(tokens_list):\n",
    "    tokenized_filter = [get_stemmed_words_list(i) for i in tokens_list]\n",
    "    unique_tokens = []\n",
    "    ind = 0\n",
    "    replacement_map = {}\n",
    "    for token in tokens_list:\n",
    "        first_set = tokenized_filter[ind]\n",
    "        j = 0\n",
    "        for second in tokens_list:\n",
    "            if j > ind:\n",
    "                second_set = tokenized_filter[j]\n",
    "                if second_set == first_set:\n",
    "                    root = token\n",
    "                    while root in replacement_map.keys():\n",
    "                        root = replacement_map[root]\n",
    "                    unique_tokens.append(root)\n",
    "                    replacement_map[second] = root\n",
    "            j += 1\n",
    "        ind +=1\n",
    "    \n",
    "    return list(set(unique_tokens)), replacement_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens_list, first_replacement_map = get_unique_keywords(tokens_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find similar words based on cosine similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings = model.encode(unique_tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = cosine_similarity(token_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_similar_groups(sim, threshold = 0.9):\n",
    "    groups = []\n",
    "    ind = 0\n",
    "    for elem in sim:\n",
    "        args = np.argsort(-elem)\n",
    "        similar = []   \n",
    "        i = 0\n",
    "        while(i<len(sim[0]) and sim[ind][args[i]] > threshold):\n",
    "            if args[i] != ind : similar.append(args[i])\n",
    "            i+=1\n",
    "        groups.append(similar)\n",
    "        ind += 1\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = create_similar_groups(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_words_from_groups(unique_tokens_list, groups):\n",
    "    res = {}\n",
    "    ind = 0\n",
    "    for sim_list in groups:\n",
    "        sim_list_keywords = [unique_tokens_list[i] for i in sim_list]\n",
    "        res[unique_tokens_list[ind]] = sim_list_keywords\n",
    "        ind += 1\n",
    "    return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.526416295353278"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average number of similar words\n",
    "sum = 0\n",
    "for elem in groups:\n",
    "    sum += len(elem)\n",
    "sum/len(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_words = get_similar_words_from_groups(unique_tokens_list, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_replacement_map_from_sim_groups(groups_words):\n",
    "    replacement_map = {}\n",
    "    ind = 0\n",
    "    for word in groups_words.keys():\n",
    "        ind += 1\n",
    "        sim_word_list = groups_words[word]\n",
    "        for sim_word in sim_word_list:\n",
    "            if sim_word not in replacement_map.keys(): replacement_map[sim_word] = []\n",
    "            replacement_map[sim_word].append(word)\n",
    "            \n",
    "            # if word not in replacement_map.keys():\n",
    "            #     replacement_map[sim_word] = word\n",
    "            # else:\n",
    "            #     # update replacement till the word has no other replacement:\n",
    "            #     root = word\n",
    "            #     i = 0\n",
    "            #     while root in replacement_map.keys() and i < 5:\n",
    "            #         root = replacement_map[root]\n",
    "            #         i += 1\n",
    "            #     replacement_map[sim_word] = word\n",
    "        # print(ind)\n",
    "    return replacement_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_map_with_multiple_options = create_replacement_map_from_sim_groups(groups_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.302439024390244"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "for key in replacement_map_with_multiple_options.keys():\n",
    "    sum += len(replacement_map_with_multiple_options[key])\n",
    "sum/len(replacement_map_with_multiple_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace keywords with the root keyword in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_keywords_in_original_file(df, replacement_map, cols =['Index Keywords', 'Author Keywords']):\n",
    "    for idx, row in df.iterrows():\n",
    "        for col in cols:\n",
    "            original = row[col]\n",
    "            original_list = original.split(';')\n",
    "            original_list = [keyword.strip() for keyword in original_list]\n",
    "            new_list = []\n",
    "            for keyword in original_list:\n",
    "                if keyword in replacement_map.keys():\n",
    "                    if type(replacement_map[keyword]) == list:\n",
    "                        new_list.append(np.random.choice(replacement_map[keyword]))\n",
    "                    else:\n",
    "                        new_list.append(replacement_map[keyword])\n",
    "                else:\n",
    "                    new_list.append(keyword)\n",
    "            \n",
    "            new_list = list(set(new_list))\n",
    "            df.loc[idx, col + ' New'] = ';'.join(new_list)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first = replace_keywords_in_original_file(df, first_replacement_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_second = replace_keywords_in_original_file(df_first, replacement_map_with_multiple_options, cols=['Index Keywords New', 'Author Keywords New'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "134d6e9b76c1038aa18b957f2c8807570bb1d03ee1a8b98ca099e402cdd324f5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('py37': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
